{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Внимание!!! Важно, что бы файлы с данными и исполняемый файл находились в одной папке, \n",
    "# тогда пути к тестовым и тренировочным наборам будут содержать только имена файлов.\n",
    "# \n",
    "# В пути к тренировочным и тестовым данным запрежается использовать абсалютную адресацию, \n",
    "# то есть адресацию, в которой присутствуют имена папок. Путь должен содержать только имя файла.\n",
    "#\n",
    "# Напоминание: под моделью машинного обучения понимаются все действия с исходными данными, \n",
    "# которые необходимо произвести, что бы сопоставить признаки целевому значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 1 (библиотеки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок в области 1 выполняется преподавателем\n",
    "# \n",
    "# данный блок предназначен только для подключения необходимых библиотек\n",
    "# запрещается подключать библиотеки в других блоках\n",
    "#\n",
    "# установка дополнительных библиотек размещается прямо здесь (обязательно закоментированы)\n",
    "#\n",
    "# pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from IPython.display import display_html\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import roc_curve, plot_roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline , make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import RocCurveDisplay, DetCurveDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler , Normalizer\n",
    "from sklearn.preprocessing import PowerTransformer , QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, LeaveOneOut\n",
    "from sklearn.model_selection import HalvingGridSearchCV, KFold , RandomizedSearchCV, ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import r2_score , accuracy_score, precision_score, recall_score ,log_loss,balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# необходимо для работы 3 блока\n",
    "\n",
    "# функция для замены цитрусовых на 1 и 0\n",
    "def zamena(df):\n",
    "   return df.replace('grapefruit',1).replace('orange',0)\n",
    "\n",
    "# нужно для 2 и 3 блока(это помогает обрезать данные с нужными колонками)\n",
    "col = ['name','diameter','weight']\n",
    "columns = ['diameter','weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 2 (поиск лучшей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок(и) НЕ выполняются преподавателем в области 2\n",
    "# блок(и) предназначены для поиска лучшей модели\n",
    "# \n",
    "# Запрещается размещать данные блоки за пределами обасти 2\n",
    "# Все блоки данной области должны быть выполнены\n",
    "#\n",
    "\n",
    "\n",
    "# функция для замены названия фруктов на 1 или 0 \n",
    "#def zamena(df):\n",
    "#   return df.replace('grapefruit',1).replace('orange',0)\n",
    "\n",
    "# Путь к тренировочному набору\n",
    "path_train = 'cit_train.csv'\n",
    "#для работы можно выбрать наиболее важные регрессоры, которые будут иметь больший вес с модели - вес и диаметер\n",
    "# применяем функцию замены цитрусовых на 1 и о, а также обрезаем фрейм\n",
    "df_raw= pd.read_csv(path_train).apply(zamena)[col]\n",
    "# думаю, что можно глянуть дубликаты в обрезанном фрейме, чтобы они не мешали нам учиться\n",
    "#display(df.duplicated().sum()) # видим 1542 дубликата => мы их убираем\n",
    "df = df_raw.drop_duplicates(keep = 'last', ignore_index= True) #дропаем дубликаты\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно глянуть конечно на данныt(но это нужно брать df_raw без обреза и без функции,)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.pairplot(df_raw, hue= 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# блок для простого анализа\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size =0.3,random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler() # используем функцию масштабирования\n",
    "scaler.fit(X_train)     # Перемасштабирование ТОЛЬКО на ТРЕНИРОВОЧНОМ наборе, создали правило перемасштабирования  \n",
    "\n",
    "X_train = scaler.transform(X_train) # перемасштабировали тренировочный набор\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 2, p = 1, weights = 'uniform')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "sc_train = knn.score(X_train , y_train)\n",
    "sc_test = knn.score(X_test , y_test)\n",
    "\n",
    "\n",
    "print(\"тренировочный: {:.3f}\".format(sc_train))\n",
    "print(\"тестовый: {:.3f}\".format(sc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ниже есть через Log Regr отбор \"значимых\" фич, но это тоже эффективно использовать\n",
    "# использовалась только для просмотра важности фич\n",
    "# тут надо брать сырой сырой фрейм без обрезки\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_raw.drop(['name'],axis = 1), df_raw['name'], test_size =0.3, random_state=42)\n",
    "\n",
    "# создаем случайное дерево\n",
    "model = RandomForestClassifier(n_estimators=340, random_state= 42)\n",
    "\n",
    "# Обучаем модель на вашей выборке\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Подбираем самые важные признаки\n",
    "importances = model.feature_importances_\n",
    "display(model.feature_importances_)\n",
    "\n",
    "# Сет для визуализации\n",
    "final_df = pd.DataFrame({\"Features\" : pd.DataFrame(X_train).columns, \"Importances\" : importances})\n",
    "final_df.set_index('Importances')\n",
    "\n",
    "# Сортируем их \n",
    "final_df = final_df.sort_values('Importances', ascending= False)\n",
    "\n",
    "# Выводим на график\n",
    "final_df.plot.bar(color = 'red')\n",
    "display(final_df)\n",
    "# то есть можно увидеть, что 2 фичи более значимы, чем все остальные\n",
    "# можно и взять их для модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно посмотреть значимость наших фич для этого фрейма,ну и выбрать по абсолютному значения наилучших для модели\n",
    "# чтобы посмотреть корректно, то коментируем функцию и столбцы когда создаем врейм df_raw\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_raw.drop(['name'],axis = 1), df_raw['name'], test_size =0.3, random_state=42)\n",
    "\n",
    "lg_model = Pipeline([('preprocessing',MinMaxScaler()), \n",
    "                 ('clf', LogisticRegression(penalty='l1', solver= 'liblinear', max_iter= 4500))])\n",
    "\n",
    "lg_model.fit(X_train, y_train)\n",
    "print(lg_model.score(X_train, y_train))\n",
    "print(lg_model.score(X_test, y_test))\n",
    "print(lg_model.named_steps['clf'].coef_)\n",
    "# видно,что 1 и 2 фича будут значительно улучшать модель\n",
    "#поэтому берем их "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size =0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем контейнер\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', MinMaxScaler()), \n",
    "    ('regressor',    KNeighborsClassifier())])\n",
    "\n",
    "\n",
    "cv = KFold(n_splits = 10, shuffle= True)\n",
    "#cv = ShuffleSplit(n_splits=15, )\n",
    "#cv = KFold(n_splits = 10) \n",
    "#cv = LeaveOneOut()\n",
    "\n",
    "\n",
    "# Параметры для решетки(можно менять и смотреть)\n",
    "p = np.arange(1,6)           \n",
    "n_neighbors = np.arange(1,16)\n",
    "weights = ['uniform','distance']\n",
    "scaling = [ MinMaxScaler(), StandardScaler(),RobustScaler(),Normalizer()]\n",
    "param_grid = [ \n",
    "    {'preprocessing':scaling,\n",
    "     'regressor': [KNeighborsClassifier()],\n",
    "     'regressor__p':p,\n",
    "     'regressor__n_neighbors': n_neighbors,\n",
    "     'regressor__weights': weights}]\n",
    "# есть много других,да это долго, но наиболее точно\n",
    "grid = RandomizedSearchCV(pipe, param_grid, cv=cv, return_train_score=True, n_jobs=-1, scoring= 'accuracy')\n",
    "grid.fit(X_train,y_train)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------- Обучили и тестировали -------------------\")\n",
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подставляем параметры в контейнер\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size =0.3, train_size=0.6,random_state=42)\n",
    "\n",
    "finish_pipe1 =  Pipeline([\n",
    "            ('preprocessing', MinMaxScaler()), \n",
    "            ('regressor',     KNeighborsClassifier(n_neighbors = 2, p = 1, weights = 'uniform'))\n",
    "            ])\n",
    "finish_pipe1.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe1.score(X_train,y_train))\n",
    "print(finish_pipe1.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотреть для интереса как и что получается\n",
    "y_predict = finish_pipe1.predict(X_test)\n",
    "precision_score(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOG Регресcия\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size =0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', MinMaxScaler()), \n",
    "                 ('clf',           LogisticRegression(max_iter=4500))]) #max_iter=5000\n",
    "#max_iter задаем, тк большой фрейм, а по стандарту стоит 100, а это очень мало и вылазит ошибка\n",
    "\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits = 10)\n",
    "#cv = ShuffleSplit(n_splits = 5)\n",
    "#cv = KFold(n_splits = 10)\n",
    "\n",
    "\n",
    "scaling = [ MinMaxScaler(), StandardScaler(),RobustScaler(),Normalizer(),PowerTransformer(),QuantileTransformer()]\n",
    "\n",
    "param_grid =[\n",
    "    {'preprocessing': scaling,'clf__penalty': ['l2'], \n",
    "         'clf__solver': ['newton-cg' ,'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "    {'preprocessing': scaling,'clf__penalty': ['l1'], \n",
    "         'clf__solver': ['liblinear']},\n",
    "    {'preprocessing': scaling,'clf__penalty': ['none'], \n",
    "         'clf__solver': ['lbfgs','newton-cg']}\n",
    "    ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = cv, return_train_score = True) #scoring = 'accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подставляем параметры в контейнер\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size =0.3,random_state=42)\n",
    "\n",
    "finish_pipe2 =  make_pipeline( QuantileTransformer(), LogisticRegression(solver = 'lbfgs', penalty = 'none',max_iter=4500) )\n",
    "finish_pipe2.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe2.score(X_train,y_train))\n",
    "print(finish_pipe2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотреть для интереса как и что получается\n",
    "y_predict = finish_pipe2.predict(X_test)\n",
    "accuracy_score(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну тут можно подкрутить \"С\", но если penalty != none\n",
    "# можно подкрутить модель\n",
    "\n",
    "pipe_fin = make_pipeline(StandardScaler(), LogisticRegression(solver = 'liblinear', penalty = 'l1') )\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "n_range = np.linspace(0.0001, 6, 500)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    pipe_fin , X_train, y_train,\n",
    "    param_name = \"logisticregression__C\", \n",
    "    param_range = n_range,\n",
    "    cv = cv, \n",
    "    scoring=\"accuracy\", \n",
    "    n_jobs=-1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"сила регуляризации\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.7, 1.05)\n",
    "\n",
    "plt.plot(n_range, train_scores_mean, label=\"Training score\", color=\"darkorange\")\n",
    "plt.fill_between(n_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\")\n",
    "plt.plot(n_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "plt.fill_between(n_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\")\n",
    "\n",
    "plt.xticks(np.linspace(0, 6, 20))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_end = make_pipeline(StandardScaler(), LogisticRegression(solver = 'liblinear', penalty = 'l1', C = 2))\n",
    "pipe_end.fit(X_train,y_train)\n",
    "print(pipe_end.score(X_train,y_train))\n",
    "print(pipe_end.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гаус\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size =0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', MinMaxScaler()), \n",
    "                 ('clf',           GaussianNB())])\n",
    "\n",
    "#cv = StratifiedShuffleSplit(n_splits = 15)\n",
    "#cv = ShuffleSplit(n_splits = 20)\n",
    "cv = KFold(n_splits= 10 , shuffle= True)\n",
    "#cv = LeaveOneOut()\n",
    "\n",
    "scaling = [ MinMaxScaler(), StandardScaler(), RobustScaler(), Normalizer(), PowerTransformer(), QuantileTransformer()]\n",
    "\n",
    "param_grid =[\n",
    "    {'preprocessing': scaling, \n",
    "     'clf': [GaussianNB()]}\n",
    "    ]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = cv, return_train_score = True)# scoring= 'accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = pd.DataFrame(grid.cv_results_).sort_values([\"rank_test_score\",'std_test_score']).T\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Наилучшие параметры:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Средняя правильность для наилучшей модели кроссвалидации на\" \n",
    "      \"валидационных тестовых наборах: {:.6f}\\n\".format(grid.best_score_)) \n",
    "print(\"Правильность для наилучшей модели на тестовом наборе: {:.6f}\\n\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подставляем параметры в контейнер\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size =0.3,random_state=42)\n",
    "\n",
    "finish_pipe3 = Pipeline(steps=[('preprocessing', Normalizer()), ('clf', GaussianNB())])\n",
    "finish_pipe3.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe3.score(X_train,y_train))\n",
    "print(finish_pipe3.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор модели \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# СРАВНЕНИЕ 3 моделей\n",
    "# 3 контейнера со своими лучшими моделям\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size = .3, random_state=42)\n",
    "\n",
    "\n",
    "model_NB = make_pipeline(Normalizer(),GaussianNB())\n",
    "model_LR = make_pipeline(QuantileTransformer(),LogisticRegression(solver = 'lbfgs', penalty = 'none',max_iter=4500))\n",
    "model_KNN = make_pipeline(MinMaxScaler(),KNeighborsClassifier(n_neighbors = 2, p=1, weights = 'uniform'))\n",
    "\n",
    "model_NB.fit(X_train,y_train)\n",
    "model_LR.fit(X_train,y_train)\n",
    "model_KNN.fit(X_train,y_train)\n",
    "\n",
    "y_NB_pred = model_NB.predict(X_test)\n",
    "y_LR_pred = model_LR.predict(X_test)\n",
    "y_KNN_pred = model_KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем и выбираем лучшую модель\n",
    "df1 = pd.DataFrame(classification_report(y_test, y_NB_pred, output_dict=True)).T\n",
    "df2 = pd.DataFrame(classification_report(y_test, y_LR_pred, output_dict=True)).T\n",
    "df3 = pd.DataFrame(classification_report(y_test, y_KNN_pred, output_dict=True)).T\n",
    "\n",
    "df1_styler = df1.style.set_table_attributes(\"style='display:inline'\").set_caption('GaussianNB')\n",
    "df2_styler = df2.style.set_table_attributes(\"style='display:inline'\").set_caption('LogisticRegression')\n",
    "df3_styler = df3.style.set_table_attributes(\"style='display:inline'\").set_caption('KNN')\n",
    "\n",
    "display_html(df1_styler._repr_html_()+df2_styler._repr_html_()+df3_styler._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_test, finish_pipe1.predict_proba(X_test)[:,1]))\n",
    "print(roc_auc_score(y_test, finish_pipe2.predict_proba(X_test)[:,1]))\n",
    "print(roc_auc_score(y_test, finish_pipe3.predict_proba(X_test)[:,1]))\n",
    "\n",
    "fig, ax_roc = plt.subplots(1,1, figsize=(10, 5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(finish_pipe1, X_test, y_test, ax = ax_roc, name = 'pipe_1');\n",
    "RocCurveDisplay.from_estimator(finish_pipe2, X_test, y_test, ax = ax_roc, name = 'pipe_2');\n",
    "RocCurveDisplay.from_estimator(finish_pipe3, X_test, y_test, ax = ax_roc, name = 'pipe_3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax_roc, ax_det] = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(finish_pipe1, X_test, y_test, ax = ax_roc, name = 'finish_pipe_1');\n",
    "RocCurveDisplay.from_estimator(finish_pipe2, X_test, y_test, ax = ax_roc, name = 'finish_pipe_2');\n",
    "RocCurveDisplay.from_estimator(finish_pipe3, X_test, y_test, ax = ax_roc, name = 'finish_pipe_3');\n",
    "\n",
    "DetCurveDisplay.from_estimator(finish_pipe1, X_test, y_test, ax = ax_det, name = 'finish_pipe_1');\n",
    "DetCurveDisplay.from_estimator(finish_pipe2, X_test, y_test, ax = ax_det, name = 'finish_pipe_2');\n",
    "DetCurveDisplay.from_estimator(finish_pipe3, X_test, y_test, ax = ax_det, name = 'finish_pipe_3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_pr = plt.subplots(1,1, figsize=(10, 5))\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(finish_pipe1, X_test, y_test, ax = ax_pr, name = 'finish_pipe_1');\n",
    "PrecisionRecallDisplay.from_estimator(finish_pipe2, X_test, y_test, ax = ax_pr, name = 'finish_pipe_2');\n",
    "PrecisionRecallDisplay.from_estimator(finish_pipe3, X_test, y_test, ax = ax_pr, name = 'finish_pipe_3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 3 (выполнение лучшей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок(и) в области 3 выполняется преподавателем\n",
    "#\n",
    "# В области находится одна, единственная, итоговая модель машинного обучения с однозначными, \n",
    "# зафиксированными параметрами\n",
    "#\n",
    "# В данной области категорически запрещается искать, выбирать, улучшать, оптимизировать, \n",
    "# тюниговать и т.д. модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zamena - это функция для замены цитрусовых на 1 и 0.\n",
    "#\n",
    "#все команды к df & df1 я описал во 2 блоке, поэтому сейчас я просто применю почти без пояснения\n",
    "#\n",
    "\n",
    "\n",
    "# Путь к тренировочному набору\n",
    "path_train = 'cit_train.csv'    # содержит только имя файла, без имен папок\n",
    "df_raw= pd.read_csv(path_train).apply(zamena)[col] # col из 1 блока(тут наши регрессоры) \n",
    "df = df_raw.drop_duplicates(keep = 'last', ignore_index= True) #дропаем дубликаты\n",
    "display(df)\n",
    "\n",
    "# Путь к тестовому набору\n",
    "#тк это тест фрейм, то произведем пару манипуляций над ним,чтобы потом сопоставить с нужным\n",
    "path_test  = 'cit_test.csv'  # содержит только имя файла, без имен папок\n",
    "df1_raw = pd.read_csv(path_test)[columns] # тоже срезаем его по нужным колонкам\n",
    "display(df1_raw)\n",
    "ind = df1_raw[df1_raw[['diameter','weight']].duplicated(keep = 'last') == True].index #индексы,которые мы будем убирать \n",
    "df1 = df1_raw.drop(index = ind).reset_index(drop = True)\n",
    "display(df1)\n",
    "\n",
    "#zamena - это функция для замены цитрусовых на 1 и 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок(и) обучения и поверки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['name'],axis = 1), df['name'], test_size = 0.3)\n",
    "\n",
    "finish_pipe =  Pipeline([\n",
    "            ('preprocessing', MinMaxScaler()), \n",
    "            ('regressor',     KNeighborsClassifier(n_neighbors = 2, p = 1, weights = 'uniform'))\n",
    "            ])\n",
    "finish_pipe.fit(X_train, y_train)\n",
    "\n",
    "print(finish_pipe.score(X_train,y_train))\n",
    "print(finish_pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок предсказания с использованием тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = finish_pipe.predict(df1)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Название вектора предсказанных значений  y_predict полученого на основании тестового набора\n",
    "y_predict = y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подстановка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['name']\n",
    "y_true_raw = pd.read_csv('.....').apply(zamena)[column] \n",
    "y_true = y_true_raw.drop(index = ind).reset_index(drop = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
